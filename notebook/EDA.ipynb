{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5602f5a8-addc-43e0-9a2b-9796d94241be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier Excel dans un DataFrame Pandas\n",
    "pdf = pd.read_excel(\"/Volumes/workspace/default/data/donnees_bls/2015/allhlcn153.xlsx\")\n",
    "\n",
    "# Convertir en DataFrame Spark pour le Big Data\n",
    "df_spark = spark.createDataFrame(pdf)\n",
    "# df_spark.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33ff45d6-12ea-4431-8f63-7c268926e1cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdee95ad-e257-41de-b10b-76266ce1f91a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0470a607-c5aa-467e-b1db-d3eb931b0a4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. Chemin vers votre dossier principal\n",
    "root_path = \"/Volumes/workspace/default/data/donnees_bls/\"\n",
    "\n",
    "# 2. Boucle simple sur les dossiers d'années\n",
    "for year_folder in sorted(os.listdir(root_path)):\n",
    "    year_path = os.path.join(root_path, year_folder)\n",
    "    \n",
    "    if os.path.isdir(year_path):\n",
    "        # Boucle sur les fichiers Excel dans chaque dossier\n",
    "        for file in os.listdir(year_path):\n",
    "            if file.endswith(\".xlsx\"):\n",
    "                file_path = os.path.join(year_path, file)\n",
    "                \n",
    "                # Lecture du fichier avec Pandas\n",
    "                df = pd.read_excel(file_path)\n",
    "                \n",
    "                # Calcul des nulls par colonne\n",
    "                null_report = df.isnull().sum()\n",
    "                count = df.shape\n",
    "                # On n'affiche que les colonnes qui ont au moins 1 null\n",
    "                null_columns = null_report[null_report > 0]\n",
    "                \n",
    "                print(f\"--- Fichier: {file} ({year_folder}) ---\")\n",
    "                if not null_columns.empty:\n",
    "                    print(null_columns)\n",
    "                    print(count)\n",
    "                else:\n",
    "                    print(\"Aucun NULL trouvé.\")\n",
    "                print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52315814-06b5-436c-b37f-f1260e282893",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. Configuration des colonnes\n",
    "# On liste toutes les colonnes \"fixes\" que vous voulez garder\n",
    "id_vars = [\n",
    "    'Area Code', 'St', 'Cnty', 'Own', 'NAICS', 'Year', 'Qtr', \n",
    "    'Area Type', 'St Name', 'Area', 'Ownership', 'Industry', \n",
    "    'Status Code', 'Establishment Count', 'Total Quarterly Wages', \n",
    "    'Average Weekly Wage', 'Employment Location Quotient Relative to U.S.', \n",
    "    'Total Wage Location Quotient Relative to U.S.'\n",
    "]\n",
    "\n",
    "# Liste complète des noms de mois possibles dans vos fichiers Excel\n",
    "month_cols_all = [\n",
    "    'January Employment', 'February Employment', 'March Employment',\n",
    "    'April Employment', 'May Employment', 'June Employment',\n",
    "    'July Employment', 'August Employment', 'September Employment',\n",
    "    'October Employment', 'November Employment', 'December Employment'\n",
    "]\n",
    "\n",
    "# 2. Lecture du fichier (exemple sur un fichier de 2015)\n",
    "folder_path = \"/Volumes/workspace/default/data/donnees_bls/2015/\"\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')]\n",
    "test_file = os.path.join(folder_path, files[0])\n",
    "\n",
    "pdf = pd.read_excel(test_file)\n",
    "\n",
    "# 3. Identifier dynamiquement les colonnes présentes dans ce fichier spécifique\n",
    "present_id_vars = [c for c in id_vars if c in pdf.columns]\n",
    "present_month_vars = [c for c in month_cols_all if c in pdf.columns]\n",
    "\n",
    "# 4. Le MELT\n",
    "# On transforme les colonnes de mois en deux colonnes : \"Mois\" et \"Valeur Emploi\"\n",
    "df_melted = pdf.melt(\n",
    "    id_vars=present_id_vars,\n",
    "    value_vars=present_month_vars,\n",
    "    var_name=\"Mois\",\n",
    "    value_name=\"Valeur Emploi\"\n",
    ")\n",
    "\n",
    "# 5. Résultat\n",
    "print(f\"Analyse terminée pour : {files[0]}\")\n",
    "display(df_melted.tail())\n",
    "df_melted.shape\n",
    "\n",
    "df_melted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f9628be-ec59-45c8-97a4-f584d4981951",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_melted.value_counts(\"Mois\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c57e429-0cab-4ce0-a097-e9180774f446",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. Configuration\n",
    "root_path = \"/Volumes/workspace/default/data/donnees_bls/\"\n",
    "all_frames = [] # Liste pour stocker les DataFrames de chaque fichier\n",
    "\n",
    "id_vars = [\n",
    "    'Area Code', 'St', 'Cnty', 'Own', 'NAICS', 'Year', 'Qtr', \n",
    "    'Area Type', 'St Name', 'Area', 'Ownership', 'Industry', \n",
    "    'Status Code', 'Establishment Count', 'Total Quarterly Wages', \n",
    "    'Average Weekly Wage', 'Employment Location Quotient Relative to U.S.', \n",
    "    'Total Wage Location Quotient Relative to U.S.'\n",
    "]\n",
    "\n",
    "month_cols_all = [\n",
    "    'January Employment', 'February Employment', 'March Employment',\n",
    "    'April Employment', 'May Employment', 'June Employment',\n",
    "    'July Employment', 'August Employment', 'September Employment',\n",
    "    'October Employment', 'November Employment', 'December Employment'\n",
    "]\n",
    "\n",
    "# 2. Boucle sur chaque dossier d'année (2015, 2016, ..., 2025)\n",
    "for year_folder in sorted(os.listdir(root_path)):\n",
    "    year_path = os.path.join(root_path, year_folder)\n",
    "    \n",
    "    # On vérifie que c'est bien un dossier\n",
    "    if os.path.isdir(year_path):\n",
    "        print(f\"Traitement de l'année : {year_folder}...\")\n",
    "        \n",
    "        # 3. Boucle sur chaque fichier Excel dans le dossier de l'année\n",
    "        for file_name in os.listdir(year_path):\n",
    "            if file_name.endswith('.xlsx'):\n",
    "                file_path = os.path.join(year_path, file_name)\n",
    "                \n",
    "                try:\n",
    "                    # Lecture du fichier\n",
    "                    pdf = pd.read_excel(file_path)\n",
    "                    \n",
    "                    # Identification des colonnes présentes\n",
    "                    present_id_vars = [c for c in id_vars if c in pdf.columns]\n",
    "                    present_month_vars = [c for c in month_cols_all if c in pdf.columns]\n",
    "                    \n",
    "                    # Application du Melt\n",
    "                    df_melted = pdf.melt(\n",
    "                        id_vars=present_id_vars,\n",
    "                        value_vars=present_month_vars,\n",
    "                        var_name=\"Mois\",\n",
    "                        value_name=\"Valeur Emploi\"\n",
    "                    )\n",
    "                    \n",
    "                    # Ajout à notre liste globale\n",
    "                    all_frames.append(df_melted)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur sur le fichier {file_name} : {e}\")\n",
    "\n",
    "# 4. Concaténation de TOUS les fichiers en un seul DataFrame\n",
    "if all_frames:\n",
    "    df_final = pd.concat(all_frames, ignore_index=True)\n",
    "    \n",
    "    print(\"--- CONSOLIDATION TERMINÉE ---\")\n",
    "    print(f\"Nombre total de lignes : {df_final.shape[0]}\")\n",
    "    \n",
    "    # 5. Conversion en Spark pour profiter de la puissance de Databricks\n",
    "    spark_df = spark.createDataFrame(df_final)\n",
    "    display(spark_df)\n",
    "else:\n",
    "    print(\"Aucune donnée n'a été trouvée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bc781d8-7685-44fc-a7a3-cbc63e828b83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4916aa6f-02d3-4408-96b3-76febbf1b5a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_final.value_counts(\"Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bac4cbbe-0ad1-400a-beaa-054bbfd6145c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_final.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb0b4564-e290-47c0-a5aa-1518e7a56f5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_final.isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "EDA",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
